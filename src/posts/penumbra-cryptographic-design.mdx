---
title: "The Brilliance in Cryptographic Design"
description: "How a privacy first team built the most defensively engineered encrypted currency by assuming their adversaries control the standards"
date: "2025-10-29"
tags: ["cryptography", "privacy", "security", "penumbra", "zero-knowledge", "nsa", "surveillance"]
draft: false
---

*in this article we go through how to build financial infrastructure that works even when
nation-states have compromised the cryptographic standards, while providing forward security
guarantees for the post-quantum era.*

---

## penumbra: internet exchange for digital assets

penumbra is an internet native exchange where you can trade digital assets, provide liquidity, and
participate in governance. no intermediaries, no custody risk, no permission needed.

you hold your state locally - balances, positions, transaction history. when you transact, you
submit encrypted commitments and zero-knowledge proofs to the global state. the network validates
the proofs without learning anything about your balances or trades. nothing links back to your
address.

this architecture creates fair markets where price discovery happens through actual supply and
demand, not information extraction.

## why privacy matters for markets

privacy isn't just about hiding transactions - it's about creating fair market structure. when
trading is algorithmic, competition becomes purely about information asymmetry. whoever sees order
flow first, front-runs. whoever has dark pool access, extracts. whoever can monitor the mempool,
captures MEV.

penumbra's shielded execution eliminates these advantages. when all transactions remain encrypted,
no participant has information edge. instead of allowing validators to extract MEV, the protocol
batches all orders together and calculates fair average prices. there's no transaction ordering
advantage because there's no meaningful ordering, just batched execution at protocol-determined
prices.

by solving the privacy problem of how to appear as the same actor, we solve the value extraction
problem. this creates a genuinely level playing field where price discovery happens through markets,
not via information extraction.

## how shielded execution actually works

the zero-knowledge proof doesn't contain instructions. it contains a claim about state transitions
plus cryptographic proof the claim is valid.

a transaction contains a list of actions (Spend, Output, Swap, Delegate, etc.), each with its own ZK
proof:

```
Transaction {
  actions: [
    Spend {
      nullifier,           // public: spent note identifier
      zkproof              // public: proves nullifier key ownership
                           // encrypted within proof: amount, asset, sender
    },
    Output {
      note_commitment,     // public: new state commitment (pedersen)
      encrypted_note       // encrypted: amount, asset, recipient, memo
    },
    ...
  ],
  binding_signature,       // public: proves sum(inputs) = sum(outputs)
  transaction_parameters,  // public: fee, expiry, chain_id
}
```

validator execution is deterministic:

1. verify each action's zkproof (checks constraints, learns nothing about encrypted values)
2. check nullifiers not in nullifier set (prevent double-spend)
3. verify binding signature (proves balance without revealing amounts)
4. add nullifiers to nullifier set (JMT), commitments to state tree (TCT)

the proof encodes valid transition constraints. validator checks "proof valid?" without learning
what satisfied it. like verifying `sha256(x) == known_hash` - you confirm the equation holds without
learning x.

state transition function is public and deterministic. what's private is which execution trace you
followed. validator doesn't need amounts/assets/addresses because the circuit already proved those
satisfy transition rules.

see real transactions at [explorer.penumbra.zone/txs](https://explorer.penumbra.zone/txs). amounts,
assets, and addresses stay hidden. only nullifiers and commitments are visible. viewing key holders
decrypt their notes locally, enabling selective disclosure to auditors without public exposure.

## what if the NSA already owns your curve?

every privacy protocol uses elliptic curves for zero-knowledge proofs. most use pairing-friendly
curves like BLS12-381 or BN254, with parameters derived from optimization criteria that aren't fully
transparent.

take NIST P-256 - the curve encrypting most HTTPS traffic on the web. every TLS 1.3 implementation
must support it; it's mandatory for compliance.

its seed value: `c49d3608 86e70493 6a6678e1 139d26b7 819f7e90`. 

where did this come from? NSA's jerry solinas told bernstein in 2015: "we built all the seeds via
hashing from the ASCII representation of a humorous message. unfortunately, we can remember neither
the (exact) message nor the details of how we hashed." NIST claims to have no documentation of how
their own curve recommendations were chosen.

we've already seen this playbook. in 2007, NSA got Dual_EC_DRBG standardized - a random number
generator with a backdoor hidden in an unexplained elliptic curve constant. they paid RSA Security
$10 million to make it the default. for six years it shipped in production systems worldwide,
generating "random" numbers the NSA could predict from observing 32 bytes.

the point isn't whether NIST curves are backdoored. the point is: you can't verify they aren't.
either you trust unexplained seeds from intelligence agencies, or you design systems that work even
if those seeds are compromised.

penumbra chose the latter.

## the BLS12-377 problem

penumbra needed fast client-side proof generation, so they picked BLS12-377 over the
industry-standard BLS12-381. ~30% faster proving, critical for mobile clients.

but BLS12-377 has cofactor 8. the full curve has order h\*r where h=8, r is prime. points outside
the prime-order subgroup break everything: invalid point attacks leak secrets through timing or
output observation, small subgroup confinement reveals key bits via chinese remainder theorem,
encoding ambiguity creates side channels. miss one validation check anywhere in your stack, and
funds lost forever.

industry response: use BLS12-381 with cofactor 1, eliminate the attack class entirely. ethereum,
zcash, filecoin all made this choice.

penumbra's response: engineer the problem away.

## Decaf377: making attacks impossible

instead of trusting developers to handle BLS12-377's complexity, penumbra built Decaf377; a
prime-order group abstraction based on Ristretto:

1. quotient group construction factors out the cofactor
2. canonical encoding gives every element exactly one representation
3. integrated validation makes encoding/decoding automatically verify validity
4. uniform interface works identically in circuits and software

you cannot deserialize an invalid point through decaf377's API. the type system makes small
subgroup attacks unrepresentable. instead of trusting every developer to call
`.is_in_correct_subgroup()`, the abstraction makes it impossible to hold an unchecked point.

take the entire vulnerability class and make it a type error.

### the cost of paranoia

Decaf377's validation costs 750 constraints in arithmetic circuits. cheaper alternatives use 325.
penumbra chose expensive anyway, because:

> "while a specification may require [validation] to be performed, implementations that skip the
> check will appear to work fine... structuring validation as an integral part of encoding and
> decoding is a safer design."

they're optimizing for "impossible to fuck up" over "theoretically correct if implemented
perfectly".

### nothing up my sleeve

every parameter transparently derived:

- base field: 8444461749428370424248824938781546531375899335154063827935233455917409239041
- curve equation: ax² + y² = 1 + dx²y² with a = -1, d = 3021
- generator point: `0x0800000000000000000000000000000000000000000000000000000000000000`

that generator, just the number 8 in hex, is the first small value producing a valid generator.
compare this to Dual_EC_DRBG's mysterious constants with no derivation. this approach follows
[rigidity principles](https://safecurves.cr.yp.to/rigid.html) for verifiable parameter generation.

## circuit-level paranoia

for sign checks in zero-knowledge circuits, penumbra had three options:

1. legendre symbol: one constraint, blazing fast, but field-specific (breaks if you change fields)
2. least significant bit: simple, reasonably fast
3. most significant bit: requires expensive range checking, but works regardless of field arithmetic

they chose option 3. the slowest one. the expensive one. the one that survives if you swap out the
entire field arithmetic later.

every optimization decision went the same way: what works if our assumptions are wrong?

## security verification

**trusted setup**: all this defensive design still bottlenecks on one assumption - the zk-SNARK
parameter ceremony. if every single participant in that ceremony was compromised, the whole thing
falls apart.

penumbra's answer: get 15,000+ people to participate. an adversary has to compromise *all of them* -
miss one honest participant, the setup is secure.

Rotko participated and destroyed our key material. which means if you trust us, you don't need to
trust anyone else. if you trust any of the other 15,000+ participants, you don't need to trust us.
the ceremony transcript is public - verify it yourself if you don't trust any of us.

this is as good as trusted setups get: trust one party out of 15,000, or verify the math yourself.

**audits**: [NCC
Group](https://www.nccgroup.com/research-blog/public-report-penumbra-labs-r1cs-implementation-review/),
[zkSecurity](https://www.zksecurity.xyz/), [Zellic](https://www.zellic.io/),
[Violet](https://x.com/alpeh_v), and [Electric Coin Company](https://electriccoin.co/) all took
their shot. cryptographic primitives, zero-knowledge circuits, protocol design, IBC implementation.
[full reports public](https://www.penumbra.zone/blog/2024-audits).

findings: implementation bugs, not design flaws. the defensive layers worked - bugs caused panics
(fail-closed) instead of silent vulnerabilities (fail-open). turns out building abstraction layers
that make entire bug classes impossible actually prevents those bugs.

## when product engineering meets threat modeling

penumbra is building a product - a privacy-preserving dex with mobile clients. normal product
thinking says: ship fast, optimize for users, minimize complexity.

they did the opposite. 750 constraints for validation where 325 would work - this matters on mobile
devices generating proofs, not validators checking them. picked the slowest sign check that survives
field arithmetic changes. built abstraction layers that make the codebase harder to understand but
make entire bug classes impossible.

because their threat model isn't "our developers might make mistakes." it's "nation-states will
actively attempt to compromise this infrastructure."

they chose to make proof generation slower on client devices to guarantee safety regardless of what
changes in the underlying math. the payoff: BLS12-377 performance (still faster than BLS12-381
despite the overhead) with BLS12-381-level safety guarantees.

the question isn't whether NSA backdoored NIST curves. the question is whether your protocol
survives if they did.

penumbra is the only protocol I've seen that took that question seriously enough to pay the
engineering cost of answering it. they built something that remains private even if the adversary
controls the math.

which means when nation-states inevitably try to compromise privacy infrastructure - and they will,
because they always do - there's at least one protocol that was designed for exactly that threat
model.

## cryptographic agility

every hard-coded assumption about field arithmetic becomes a liability if you need to swap curves;
whether from quantum computers, cryptanalytic breakthroughs, or newly discovered backdoors.

penumbra's defensive layers enable curve migration:

- circuit modularity: swap primitives without rewriting validation logic
- field-independent sign checks: survive curve replacement
- quotient group construction: works for any cofactor curve
- verifiable parameter generation: regenerate from new constants

new curve requires new trusted setup. users spend old notes, create new notes on new curve. gradual
transition, no flag day.

protocols optimized for today's curves baked performance assumptions into their architecture.
penumbra assumed the curves would change - from quantum threats, cryptanalytic advances, or evidence
of compromise - and paid the complexity cost upfront.

paranoia about compromised standards naturally leads to designs that survive standard changes.

---

## references

- [Penumbra Protocol: Cryptography](https://protocol.penumbra.zone/main/crypto.html)
- [Decaf377 specification](https://protocol.penumbra.zone/main/crypto/decaf377.html)
- [Dual_EC_DRBG: The NSA backdoor](https://en.wikipedia.org/wiki/Dual_EC_DRBG)
