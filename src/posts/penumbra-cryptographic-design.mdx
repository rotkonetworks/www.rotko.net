---
title: "The Brilliance in Cryptographic Design"
description: "How a privacy first team built the most defensively engineered encrypted currency by assuming their adversaries control the standards"
date: "2025-10-29"
tags: ["cryptography", "privacy", "security", "penumbra", "zero-knowledge", "nsa", "surveillance"]
draft: false
---

*how a privacy first team built with the most defensively engineered encrypted currency by assuming
their adversaries control the standards*

---

## what if the NSA already owns your curve?

every privacy protocol uses elliptic curves. nearly all of them use NIST P-256 or similar
standardized curves. these curves have "randomly generated" parameters that determine their security
properties.

except the "random" seeds are never explained.

take NIST P-256's seed value: `c49d3608 86e70493 6a6678e1 139d26b7 819f7e90`. where did this come
from? NIST's documentation: "generated by hashing the unexplained bit string". unexplained.

this matters because we've already seen this playbook. in 2007, NSA got Dual_EC_DRBG standardized -
a random number generator with a built-in backdoor hidden in an "unexplained" elliptic curve point.
they paid RSA Security $10 million to make it the default. for six years, it was in production
systems worldwide.

the point isn't whether NIST curves are backdoored (though that's a fun drinking game). the point
is: *you can't verify they aren't*. either you trust NIST's unexplained seeds, or you don't use
modern cryptography.

penumbra looked at this situation and asked: what if we design the entire protocol assuming the
standards bodies are compromised?

then they actually built it.

## why privacy matters for markets

privacy isn't just about hiding transactions - it's about creating fair market structure. when
trading is algorithmic, competition becomes purely about information asymmetry. whoever sees order
flow first, front-runs. whoever has dark pool access, extracts. whoever can monitor the mempool,
captures MEV.

penumbra's shielded execution eliminates these advantages. when all transactions are encrypted until
finalization, no participant has information edge. instead of allowing validators to extract MEV,
the protocol batches all orders together and calculates fair average prices. any value that would
have been MEV gets burned. there's no transaction ordering advantage because there's no meaningful
ordering, just batched execution at protocol-determined prices.

this creates a genuinely level playing field where price discovery happens through markets, not
information extraction. but this only works if the privacy guarantees are actually robust.

## the NSA's cryptographic playbook

intelligence agencies don't break the math; they *write* the math.

### case study: Dual_EC_DRBG

the algorithm used elliptic curve points with a "random" constant Q. except Q wasn't random - it was
Q = dP where the NSA knew d. this let them predict all future outputs from seeing just 32 bytes.

cryptographers noticed immediately. didn't matter. NSA institutional weight pushed it through NIST.
RSA Security got $10 million to make it the default in BSAFE. for six years it was in production
systems worldwide, generating "random" numbers the NSA could predict.

one mathematical relationship, mass surveillance at scale.

## penumbra's counter-strategy: trust no one

so penumbra looked at the landscape and saw potential Dual_EC situations everywhere:

- NIST curves with unexplained seed values
- academic constructions assuming "honest parameter generation"
- trusted setups as single points of failure
- standard libraries with implementation "bugs" that might not be bugs

solution: assume adversarial parameter generation for every component. then design something that
works anyway.

## the BLS12-377 problem

penumbra needed fast client-side proof generation, so they picked BLS12-377 over the
industry-standard BLS12-381. ~30% faster proving, critical for mobile clients.

but BLS12-377 has cofactor 8. the full curve has order h\*r where h=8, r is prime. points outside
the prime-order subgroup break everything: invalid point attacks leak secrets through timing or
output observation, small subgroup confinement reveals key bits via chinese remainder theorem,
encoding ambiguity creates side channels. miss one validation check anywhere in your stack, and
funds lost forever.

industry response: use BLS12-381 with cofactor 1, eliminate the attack class entirely. ethereum,
zcash, filecoin all made this choice.

penumbra's response: engineer the problem away.

## Decaf377: making attacks impossible

instead of trusting developers to handle BLS12-377's complexity, penumbra built Decaf377; a
prime-order group abstraction based on Ristretto:

1. quotient group construction factors out the cofactor
2. canonical encoding gives every element exactly one representation
3. integrated validation makes encoding/decoding automatically verify validity
4. uniform interface works identically in circuits and software

you cannot deserialize an invalid point through decaf377's API. the type system makes small
subgroup attacks unrepresentable. instead of trusting every developer to call
`.is_in_correct_subgroup()`, the abstraction makes it impossible to hold an unchecked point.

take the entire vulnerability class and make it a type error.

### the cost of paranoia

Decaf377's validation costs 750 constraints in arithmetic circuits. cheaper alternatives use 325.
penumbra chose expensive anyway, because:

> "while a specification may require [validation] to be performed, implementations that skip the
> check will appear to work fine... structuring validation as an integral part of encoding and
> decoding is a safer design."

they're optimizing for "impossible to fuck up" over "theoretically correct if implemented
perfectly".

### nothing up my sleeve

every parameter transparently derived:

- base field: 8444461749428370424248824938781546531375899335154063827935233455917409239041
- curve equation: ax² + y² = 1 + dx²y² with a = -1, d = 3021
- generator point: `0x0800000000000000000000000000000000000000000000000000000000000000`

that generator, just the number 8 in hex, is the first small value producing a valid generator.
compare this to Dual_EC_DRBG's mysterious constants with no derivation.

## circuit-level paranoia

for sign checks in zero-knowledge circuits, penumbra had three options:

1. legendre symbol: one constraint, blazing fast, but field-specific (breaks if you change fields)
2. least significant bit: simple, reasonably fast
3. most significant bit: requires expensive range checking, but works regardless of field arithmetic

they chose option 3. the slowest one. the expensive one. the one that survives if you swap out the
entire field arithmetic later.

every optimization decision went the same way: what works if our assumptions are wrong?

## security verification

**trusted setup**: all this defensive design still bottlenecks on one assumption - the zk-SNARK
parameter ceremony. if every single participant in that ceremony was compromised, the whole thing
falls apart.

penumbra's answer: get 15,000+ people to participate. an adversary has to compromise *all of them* -
miss one honest participant, the setup is secure.

Rotko participated and destroyed our key material. which means if you trust us, you don't need to
trust anyone else. if you trust any of the other 15,000+ participants, you don't need to trust us.
the ceremony transcript is public - verify it yourself if you don't trust any of us.

this is as good as trusted setups get: trust one party out of 15,000, or verify the math yourself.

**audits**: [NCC
Group](https://www.nccgroup.com/research-blog/public-report-penumbra-labs-r1cs-implementation-review/),
[zkSecurity](https://www.zksecurity.xyz/), [Zellic](https://www.zellic.io/),
[Violet](https://x.com/alpeh_v), and [Electric Coin Company](https://electriccoin.co/) all took
their shot. cryptographic primitives, zero-knowledge circuits, protocol design, IBC implementation.
[full reports public](https://www.penumbra.zone/blog/2024-audits).

findings: implementation bugs, not design flaws. the defensive layers worked - bugs caused panics
(fail-closed) instead of silent vulnerabilities (fail-open). turns out building abstraction layers
that make entire bug classes impossible actually prevents those bugs.

## when product engineering meets threat modeling

penumbra is building a product - a privacy-preserving dex with mobile clients. normal product
thinking says: ship fast, optimize for users, minimize complexity.

they did the opposite. 750 constraints for validation where 325 would work - this matters on mobile
devices generating proofs, not validators checking them. picked the slowest sign check that survives
field arithmetic changes. built abstraction layers that make the codebase harder to understand but
make entire bug classes impossible.

because their threat model isn't "our developers might make mistakes." it's "nation-states will
actively attempt to compromise this infrastructure."

they chose to make proof generation slower on client devices to guarantee safety regardless of what
changes in the underlying math. the payoff: BLS12-377 performance (still faster than BLS12-381
despite the overhead) with BLS12-381-level safety guarantees.

the question isn't whether NSA backdoored NIST curves. the question is whether your protocol
survives if they did.

penumbra is the only protocol I've seen that took that question seriously enough to pay the
engineering cost of answering it. they built something that remains private even if the adversary
controls the math.

which means when nation-states inevitably try to compromise privacy infrastructure - and they will,
because they always do - there's at least one protocol that was designed for exactly that threat
model.

turns out paranoia isn't a bug in cryptographic design. it's the only rational response to history.

---

*technical claims verified against primary source documentation*

## references

- [Penumbra Protocol: Cryptography](https://protocol.penumbra.zone/main/crypto.html)
- [Decaf377 specification](https://protocol.penumbra.zone/main/crypto/decaf377.html)
- [Dual_EC_DRBG: The NSA backdoor](https://en.wikipedia.org/wiki/Dual_EC_DRBG)
